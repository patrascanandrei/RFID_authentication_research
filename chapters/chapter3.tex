\chapter{The use of temporary variables}

\section{Temporary variables definition}

    A tag's memory can be classified in two ways: \textbf{permanent}/persistent or \textbf{temporary}/volatile. The permanent memory contains the state values of the tag, while the temporary memory is
    composed by temporary/volatile variables used in calculations. Temporary variables can be further split into local temporary variables: used for a single step of the protocol
    and global temporary variables: used to store values for a future step of the protocol.

    As the definitions imply, the global temporary variables have a longer lifetime than local temporary variables. They are used to
    store information that is later 
    verified against received values to aid in the process of authentication. The use of them needs to be done with great care as corruption of 
    tags can occur and by that an adversary can access information that would thwart privacy.

\section{Temporary state disclosure and its effects on privacy}

    \textbf{Types of corruption:}
    Under tag corruption the temporary tag state is disclosed depending on the concrete scenario. In general it is
    under one of the following cases:

    1. corruption discloses \textit{the full state}: the permanent and the temporary memory (this is referred as "Temporary State Disclosure")

    2. corruption discloses \textit{just the permanent state}, leaving the values in the temporary memory still a secret.

    The vulnerability through corruption has been highlighted for the first time in \cite{Impossibility_results}. Later \cite{Tiplea} 
    extends the definition to cover PUF-based RFID protocols as well. 

    The subsequent section outlines the results of \cite{Impossibility_results} and analyzes their relevance to Vaudenay's model.

    \textbf{Theorem 1}: \textit{There is no RFID system in Vaudenay's model that achieves both reader authentication and narrow-forward privacy 
    under temporary state disclosure.}

    This result is based on the following lemma:

    \textbf{Lemma 1}: If every narrow-forward adversary $\mathcal{A}_{prv}$ has a blinder $\mathcal{B}$ such that $Adv_{\mathcal{A}_{prv}}^{prv}$ is negligible
    then $\mathcal{B}$ can be used for a blinded adversary $\mathcal{A}_{sec}^{\mathcal{B}}$ such that \\
    $Pr[Exp_{\mathcal{A}_{sec}^{B}}^{\mathcal{R}-aut} = 1]$ is non-negligible.

    Proof for Theorem 1: The definition of privacy requires the existence of a blinder such that there is no difference between an adversary that uses the 
    protocol messages and a blinded adversary $\mathcal{A}^{\mathcal{B}}$. This is equivalent to an adversary that cannot distinguish between $\mathcal{B}$
    and the real oracles. Lemma 1 states that if privacy is achieved there is such a blinder that can impersonate the reader with non-negligible probability.
    Thus, $\mathcal{B}$ contradicts reader authentication (Definition 2).

    The result of Theorem 1 and the proof for Lemma 1 are deducted in the following:

    \textit{Step 1.} There is assumed that there is a scheme that achieves both reader authentication and narrow-forward privacy. This will lead to a contradiction.
    
    \textit{Step 2.} Narrow-forward privacy means an adversary $\mathcal{A}_{prv}$ and a blinded adversary $\mathcal{A}_{prv}^{\mathcal{B}}$  with no discernible
    advantage between them. $\mathcal{A}_{prv}^{\mathcal{B}}$ simulates the Launch, SendReader and SendTag oracles.
    The blinded adversary is used for an attacker for reader authentication, $\mathcal{A}_{sec}^{\mathcal{B}}$.
    
    \textit{Step 3.} The construction of $\mathcal{A}_{sec}^{\mathcal{B}}$ is shown in Algorithm 1 and the win condition for $\mathcal{A}_{sec}^{\mathcal{B}}$
    is established (Eq. 1 to be non-negligible). 

    The construction for a blinded adversary against reader authentication is presented in algorithm 1.

    $\mathcal{A}_{sec}^{\mathcal{B}}$ uses the blinder as a black box to simulate the messages between the reader and the tag.
    $\mathcal{A}_{sec}$ succeeds if $\mathcal{T}_{ID}$ accepts $\mathcal{B}$ as reader $\mathcal{R}$. Formally to break reader authentication:

    $Pr[Exp_{\mathcal{A}_{sec}^{B}}^{\mathcal{R}-aut} = 1] = Pr[Ident[\mathcal{T}_{ID}:S_0^{\mathcal{T}_{ID}}; \mathcal{A}_{sec}^{\mathcal{B}}:-; *:pk_{R}]
    \rightarrow [\mathcal{T}_{ID}:real; \mathcal{A}_{sec}^{\mathcal{B}}:.]]$ (Equation 1) ($S_0^{\mathcal{T}_{ID}}$ denotes the initial tag state) needs to be
    non-negligible.
    

    \begin{algorithm}[H] % -> H to fix in place
        \centering
        \caption{Adversary $\mathcal{A}_{sec}^{\mathcal{B}}$ against reader authentication}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag(ID)
            \State $vtag \leftarrow$ DrawTag(ID)
            \State $\pi \leftarrow$ Launch() \Comment{simulated by $\mathcal{B}$}
            \State $m_1 \leftarrow SendReader(-,\pi)$ \Comment{simulated by $\mathcal{B}$}
            \State i $\leftarrow$ 1
            \While{$i < stepsOfProtocol$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag)$ \Comment{simulated by $\mathcal{B}$}
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$ \Comment{simulated by $\mathcal{B}$}
                \State $i \gets i+1$
            \EndWhile
            \State $out_{\mathcal{T}_{ID}} \gets SendTag(m_{final}, vtag)$ \Comment{computed by $\mathcal{T}_{ID}$}
        \end{algorithmic}
    \end{algorithm}

    
    \textit{Step 4.} A proof that $\mathcal{A}_{sec}^{\mathcal{B}}$ has non-negligible odds to win the security game i.e. Eq. 1 is non-negligible.
    This is a proof by contradiction as well. Equation 1 being negligible (i.e. achieving reader authentication) means a non-negligible $p_{\bot}$ that $out_{\mathcal{T}_{ID}} = \bot$.
    The consequence is that $\mathcal{A}_{prv}$ has a non-negligible advantage in distinguishing the real oracles from the simulated ones, contradicting privacy.

    The construction of $\mathcal{A}_{prv}$ is shown in Algorithm 2.

    The adversary for privacy $\mathcal{A}_{prv}$ corrupts $\mathcal{T}_{ID}$ just before it receives the last message, $m_{final}$. Next, $\mathcal{A}_{prv}$
    performs the computation $\mathcal{T}_{ID}$ would have done for $m_{final}$. A result of $out_{\mathcal{T}_{ID}} = real$ denotes that the protocol interacted
    with the real oracles (and the algorithm returns 0), otherwise the calls were made through $\mathcal{B}$ (and the algorithm returns 1).

    $\mathcal{A}_{prv}$ is a narrow-forward adversary because during the experiment there were no Result($\pi$) calls and once a Corrupt(vtag) was called 
    no other oracle was queried.

    \begin{algorithm}[H] % -> H to fix in place
        \centering
        \caption{Narrow-forward adversary $\mathcal{A}_{prv}$}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag(ID)
            \State $vtag \leftarrow$ DrawTag(ID)
            \State $\pi \leftarrow$ Launch() 
            \State $m_1 \leftarrow SendReader(-,\pi)$ 
            \State i $\leftarrow$ 1
            \While{$i < stepsOfProtocol$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag)$ 
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile
            \State $S^{\mathcal{T}_{ID}} \gets$ \text{Corrupt}(vtag)
            \State $out_{\mathcal{T}_{ID}} \gets \mathcal{T}_{ID}(S^{\mathcal{T}_{ID}}, m_{final})$
            \If{$out_{\mathcal{T}_{ID}} = \text{real}$}
                \State \Return 0
            \Else
                \State \Return 1
            \EndIf
        \end{algorithmic}
    \end{algorithm}

    What remains is to assess the odds of $\mathcal{A}_{prv}$ discerning between real/simulated oracles.

    Firstly, for the case in which the adversary interacts with the real system/oracles, it follows from correctness that probability $p_{real}$ of 
    $out_{\mathcal{T}_{ID}}$ is overwhelming, meaning $Pr[Exp_{\mathcal{A}_{prv}}^{prv-0} = 1] = 1-p_{real}$ is negligible. Secondly we consider the case
    with the blinder. From the assumption (there is reader authentication) $\mathcal{B}$ generates the last message such that $out_{\mathcal{T}_{ID}} = \bot$ with non-negligible probability $p_{\bot}$.
    Thus $Pr[Exp_{\mathcal{A}_{prv}}^{prv-1} = 1] = p_{\bot}$ is non-negligible. It follows that $Adv_{\mathcal{A}_{prv}}^{prv} = |1-p_{real}-p_{\bot}|$ is non-negligible,
    thus a contradiction. 

    The contradiction means that the assumption was incorrect and $\mathcal{A}_{sec}^{\mathcal{B}}$ has non-negligible odds to win the security game.

    \textit{Step 5.} This adversary yields $Pr[Exp_{\mathcal{A}_{sec}^{B}}^{\mathcal{R}-aut} = 1]$ non-negligible meaning that reader authentication is disproved. 
    This means that the assumption at step 1 is false which means Theorem 1 is correct: there is no RFID system in Vaudenay's model that achieves both reader authentication and narrow-forward privacy 
    under temporary state disclosure.

    Below is shown how the narrow-forward adversary interacts with the tag to thwart reader authentication. This is an attack on security.

    \begin{figure}[H]

    \hspace*{0cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance=0.5cm and 0.5cm
    ]

    % Nodes (text boxes)
    \node[box] (A) { $A\ draws\ $\\$tag\ ID$ };
    \node[box, right=of A] (B) { $A\ computes/forwards$ \\ $the\ steps\ of\ the\ protocol$ \\ $until\ the\ last\ message$};
    \node[box, right=of B] (C) { $A\ corrupts$ \\ $the\ tag\ and$ \\ $gets\ its\ entire\ state$};
    \node[box, right=of C] (D) { $A\ is\ able$ \\ $to\ authenticate$ \\ $reader\ \mathcal{R}$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);
    \end{tikzpicture}
    \caption{Temporary state disclosure attack}
    \end{figure}

\section{Corruption without temporary state disclosure}

    Another result from \cite{Impossibility_results} is presented in this chapter. 
    The result obtained above shows there are more assumptions to evaluate than
    previously considered in the context of tag corruption. A natural direction
    to follow up on is what level of privacy can be achieved if temporary state
    disclosure is not a factor. Thus, we study the case in which corruption discloses 
    \textit{just the permanent state}, leaving global and local temporary variables
    secret.

    The previous result is built upon the fact that $\mathcal{A}_{prv}$ can learn the
    temporary state of a tag during the Ident Protocol. This permits $\mathcal{A}_{prv}$
    to verify the last message of the protocol with the tag and due to reader authentication
    can distinguish between real oracles and a blinded environment. However if the corruption
    yields only the persistent state, the previous result might not hold.
    
    \textbf{Theorem 2}: \textit{There is no RFID system in Vaudenay's model that achieves both reader authentication and narrow-strong privacy 
    under permanent state disclosure.}

    The result of Theorem 2 is deducted in the following:

    \textit{Step 1.} There is assumed that there is a scheme that achieves both reader authentication and narrow-strong privacy.
    This will lead to a contradiction.

    \textit{Step 2.} Narrow-strong privacy means an adversary $\mathcal{A}_{prv}$ and a blinded adversary $\mathcal{A}_{prv}^{\mathcal{B}}$  with no discernible
    advantage between them.
    
    $\mathcal{A}_{prv}^{\mathcal{B}}$ simulates the Launch, SendReader and SendTag oracles.
    The blinded adversary is used for an attacker for reader authentication, $\mathcal{A}_{sec}^{\mathcal{B}}$.
    
    \textit{Step 3.} The construction of $\mathcal{A}_{sec}^{\mathcal{B}}$ is shown in Algorithm 3 and the win condition for $\mathcal{A}_{sec}^{\mathcal{B}}$
    is established (Eq. 2 to be non-negligible).

    \begin{algorithm}[H] % -> H to fix in place
        \centering
        \caption{Adversary $\mathcal{A}_{sec}^{\mathcal{B}}$ against reader authentication}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag(ID)
            \State $vtag \leftarrow$ DrawTag(ID)
            \State $S_0^{\mathcal{T}_{ID}} \gets Corrupt(vtag)$
            \State $\pi \leftarrow$ Launch() \Comment{simulated by $\mathcal{B}$}
            \State $m_1 \leftarrow SendReader(-,\pi)$ \Comment{simulated by $\mathcal{B}$}
            \State i $\leftarrow$ 1
            \While{$i < stepsOfProtocol$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag)$ \Comment{simulated by $\mathcal{B}$}
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$ \Comment{simulated by $\mathcal{B}$}
                \State $i \gets i+1$
            \EndWhile
            \State $out_{\mathcal{T}_{ID}} \gets SendTag(m_{final}, vtag)$ \Comment{computed by $\mathcal{T}_{ID}$}
        \end{algorithmic}
    \end{algorithm}

    $\mathcal{A}_{sec}$ succeeds if $\mathcal{T}_{ID}$ accepts $m_{final}$ and returns $out_{\mathcal{T}_{ID}} = real$.
    It means that $\mathcal{T}_{ID}$ accepts $\mathcal{B}$ as reader $\mathcal{R}$. Formally to break reader authentication:

    $Pr[Exp_{\mathcal{A}_{sec}^{B}}^{\mathcal{R}-aut} = 1] = Pr[Ident[\mathcal{T}_{ID}:S_0^{\mathcal{T}_{ID}}; \mathcal{A}_{sec}^{\mathcal{B}}:-; *:pk_{R}]
    \rightarrow [\mathcal{T}_{ID}:real; \mathcal{A}_{sec}^{\mathcal{B}}:.]]$ (Equation 2) ($S_0^{\mathcal{T}_{ID}}$ denotes the initial tag state)
    needs to be non-negligible.

    \textit{Step 4.} A proof that $\mathcal{A}_{sec}^{\mathcal{B}}$ has non-negligible odds to win the security game i.e. Eq. 2 is non-negligible.
    This is a proof by contradiction as well. Equation 2 being negligible means a non-negligible probability that $out_{\mathcal{T}_{ID}} = \bot$.
    Let $p_t$ be that probability. The consequence is that $\mathcal{A}_{prv}$ has a non-negligible advantage in distinguishing the real oracles 
    from the simulated ones, contradicting privacy.

    The construction of $\mathcal{A}_{prv}$ is shown in Algorithm 4.

    Notation is: 

    $S_0^{\mathcal{T}_{ID}}$ denotes the initial (0) state S of tag $\mathcal{T}_{ID}$;

    $q_t$ denotes the (expected) number of SendTag queries specified by the Ident protocol;

    $\mathcal{T}_{ID}(state, message)$ denotes the computation done by $\mathcal{T}_{ID}$ 
    when given message on specified state. 
    
    $\mathcal{A}_{prv}$ is a narrow-strong adversary because during the experiment there were no Result($\pi$) calls and after Corrupt(vtag) was called 
    the adversary continued to use the tag.
    
    \begin{algorithm}[H] % -> H to fix in place
        \centering
        \caption{$\mathcal{A}_{prv}$ against narrow-strong privacy}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag(ID)
            \State $vtag \leftarrow$ DrawTag(ID)
            \State $S_0^{\mathcal{T}_{ID}} \gets Corrupt(vtag)$
            \State $\pi \leftarrow$ Launch() 
            \State $m_1 \leftarrow SendReader(-,\pi)$ 
            \State $t \in \{1, ..., q_t\}$
            \State i $\leftarrow$ 1
            \While{$i < t$}                
                \State $(S_{i+1}^{\mathcal{T}_{ID}}, m_{2i}) \gets 
                    \mathcal{T}_{ID}(S_{i}^{\mathcal{T}_{ID}}, m_{2i-1})$ 
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile
            \State $out_{\mathcal{T}_{ID}} \gets \mathcal{T}_{ID}(S_t^{\mathcal{T}_{ID}}, m_{final})$
            \If{$out_{\mathcal{T}_{ID}} = \text{real}$}
                \State \Return 0
            \Else
                \State \Return 1
            \EndIf
        \end{algorithmic}
    \end{algorithm}

    In this context the Corrupt(vtag) call (line 3) yields only the persistent state $S_0^{\mathcal{T}_{ID}}$ of 
    $\mathcal{T}_{ID}$. $\mathcal{A}_{prv}$ guesses t (step 6) and simulates the tag in the Ident protocol until 
    the reader returns $m_{final}$. $\mathcal{A}_{prv}$ performs the computation for $\mathcal{T}_{ID}$ with the last
    message m and return 0 for the case it interacted with the real oracles or 1 otherwise.

    Next we study what advantage $Adv_{\mathcal{A}_{prv}}^{prv}$ adversary $\mathcal{A}_{prv}$ has when $p_t$ is assumed non-negligible.
    For the case of the real oracles, it follows from correctness that $out_{\mathcal{T}_{ID}} = real$ with overwhelming
    probability $p_{real}$. This means that $Pr[Exp_{\mathcal{A}_{prv}}^{prv-0} = 1] = 1-p_{real}$ is negligible. Secondly we consider the case
    with the blinder. From the assumption $\mathcal{B}$ generates the last message such that $out_{\mathcal{T}_{ID}} = \bot$ with 
    non-negligible probability $p_t$. Furthermore $\mathcal{A}_{prv}$ guesses number of tag messages t with 
    probability $1/q_t$. Thus $Pr[Exp_{\mathcal{A}_{prv}}^{prv-1} = 1] \ge p_t/q_t$. The advantage becomes
    $Adv_{\mathcal{A}_{prv}}^{prv} \ge |1-p_{real}-p_t/q_t|$. Due to correctness $p_{real}$ is overwhelming, the 
    assumption gives $p_t$ non-negligible and $q_t$ is polynomially bounded. It results in a non-negligible 
    advantage which contradicts narrow-strong privacy.

    The contradiction means that the assumption was incorrect and $\mathcal{A}_{sec}^{\mathcal{B}}$ has non-negligible odds to win the security game.

    \textit{Step 5.} This adversary yields $Pr[Exp_{\mathcal{A}_{sec}^{B}}^{\mathcal{R}-aut} = 1]$ non-negligible meaning that reader authentication is disproved. 
    This means that the assumption at step 1 is false which means Theorem 2 is correct. 

    Below is shown how the narrow-strong adversary interacts with the tag to
    thwart reader authentication. This is an attack on security.

    \begin{figure}[H]
        
    \hspace*{2cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance=1cm and 1cm
    ]

    % Nodes (text boxes)
    \node[box] (A) { $A\ draws\ $\\$tag\ ID$ };
    \node[box, right=of A] (B) { $A\ corrupts$ \\ $the\ tag\ and$ \\ $gets\ its$ \\ $permanent\ state$};
    \node[box, right=of B] (C) { $A\ guesses\ number\ of$ \\ $protocol\ steps\ t$};
    \node[box, below=of C] (D) { $A\ computes\ the\ steps$ \\ $of\ the\ protocol$ $on\ the\ tag$};
    \node[box, left=of D] (E) { $A\ is\ able\ to$ \\ $authenticate\ reader\ \mathcal{R}$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);
    \draw[arrow] (D) -- (E);
    \end{tikzpicture}
    \caption{Permanent state disclosure attack}
    \end{figure}

\section{The impossibility results for resettable tags}

    It is known that standard security notions do no longer work when the adversary can reset the internal state of the tags. Reset attacks have
    been motivated in particular by the use of smart cards since in specific cases they go to their initial state when disconnected from power. Subsequently
    they compute with the same randomness they already used before. Reset attacks are always possible when the adversary controls the environment.

    In a similar fashion as before, the reset capabilities are studied for the case of total state reset (permanent and temporary memory) and for the case in which
    the reset affects only the persistent state.

    To cover the case of reset attacks, a new oracle is introduced: Reset(vtag) to Vaudenay's model. This oracle allows the adversary to reset the state of the vtag
    to its original values and its randomness as well. It is assumed that it can be computed in polynomial time. As for the Corrupt(vtag) oracle the Reset(vtag) is also not carried out
    by the blinder $\mathcal{B}$ but merely observed by it.

    \textbf{Theorem 3}: \textit{Against an adversary that is allowed to call the Reset oracle no privacy can be achieved in Vaudenay's model.}

    To demonstrate the theorem an experiment is constructed to show that a narrow-weak adversary $\mathcal{A}_{prv}$ can distinguish with a non-negligible advantage 
    between an interaction with the real oracles or through a blinder $\mathcal{B}$. This is shown in algorithm 5.

    \begin{algorithm}[H]
        \centering
        \caption{$\mathcal{A}_{prv}$ against narrow-weak privacy}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag($ID_0$)
            \State CreateTag($ID_1$)
            \State $vtag_{0} \leftarrow$ DrawTag($ID_k, Pr(k)= 1/2, k \in \{0,1\}$) 
            \State $m_1 \leftarrow SendReader(-,\pi)$ 
            \State i $\leftarrow$ 1
            \While{$i < stepsOfProtocol$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag_{0})$
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile
            \State $Reset(vtag_{0})$
            \State $Free(vtag_{0})$
            \State $vtag_{1} \leftarrow$ DrawTag($ID_k, Pr(k)= 1/2, k \in \{0,1\}$) 
            \State i $\leftarrow$ 1
            \While{$i < stepsOfTag$}
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag_{1})$
                \State $i \gets i+1$
            \EndWhile       
            \If{$ \tau_{0} = \tau_{1} $}
                \State $out \leftarrow 1$
            \Else
                \State $out \leftarrow 0$
            \EndIf
            \State $return (\Gamma[vtag_{0}] = \Gamma[vtag_{1}] \land out) \lor 
                (\Gamma[vtag_{0}] \neq \Gamma[vtag_{1}] \land \lnot out)$
        \end{algorithmic}
    \end{algorithm}

    The adversary is narrow-weak because the algorithm uses no Corrupt() oracle (thus a weak adversary) and calls no Result() oracle 
    (thus a narrow adversary).

    $\mathcal{A}_{prv}$ eavesdrops a complete execution of the protocol between $vtag_{0}$ and $\mathcal{R}$(lines 6-10). Let $\tau_{0}$ be the transcript of the protocol, including the messages
    sent both by the reader and the tag.

    To simulate $\mathcal{R}$ adversary $\mathcal{A}_{prv}$ uses the messages of $\tau_{0}$ to simulate a new interaction with a newly drawn tag, $vtag_{1}$, obtaining $\tau_{1}$. If the same tag was
    drawn both times then $\mathcal{A}_{prv}$ expects the transcripts to match. A blinder would not know the result of DrawTag() ( line 13 ) and would have the guess which tag was
    selected. 
    
    Next, the $Adv_{\mathcal{A}_{prv}}^{prv}$ is studied to determine privacy. For the case in which the attack uses the real oracles the reset of the tag always yields the same transcript a second time. 
    The messages of the reader are the same by design of the attack and those of the tag also match because of the reset. Thus $\mathcal{A}_{prv}$ succeeds with probability $1-\epsilon(l)$
    where $\epsilon$ is a negligible function and $l$ is the security parameter.

    Formally:

    $Pr[Exp_{\mathcal{A}_{prv}}^{prv-0} = 1] = Pr[(\Gamma[vtag_{0}] = \Gamma[vtag_{1}]) \land out] + Pr[(\Gamma[vtag_{0}] \neq \Gamma[vtag_{1}]) \land \lnot out] = 
        \frac{1}{2}*1+\frac{1}{2}*(1-\epsilon(l)) = 1-\epsilon(l)/2$.
    
    For the case of the blinder, $\mathcal{B}$ can only guess the tag selected by the second DrawTag call. Thus output $out$ can only be $\frac{1}{2}.$ The probability becomes:

    $Pr[Exp_{\mathcal{A}_{prv}}^{prv-1} = 1] = Pr[(\Gamma[vtag_{0}] = \Gamma[vtag_{1}]) \land out] + Pr[(\Gamma[vtag_{0}] \neq \Gamma[vtag_{1}]) \land \lnot out] = 
        \frac{1}{2}*\frac{1}{2}+\frac{1}{2}*\frac{1}{2} = \frac{1}{2}$.

    The difference between the two cases leads to a non-negligible probability and therefore the privacy definition is contradicted, proving theorem 3: against an adversary that is allowed to call the 
    Reset oracle no privacy can be achieved in Vaudenay's model.

    \begin{figure}[H]
    \hspace*{-0cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance=1cm and 2cm
    ]

    % Nodes (text boxes)
    \node[box] (A) { $A\ creates\ two$ \\ $tags\ ID0\ and\ ID1$ };
    \node[box, right=of A] (B) { $A\ draws\ one\ tag$ \\ $at\ random\ and$ \\ $eavesdrops\ a$ \\ $complete\ run\ of\ the$ \\ $protocol$};
    \node[box, right=of B] (C) { $A\ resets\ and\ frees$ \\ $the\ tag$};
    \node[box, below=of C] (D) { $A\ draws\ one\ of\ the$ \\ $two\ tags\ at\ random\ and$ \\ $simulates\ a$ \\ $complete\ run\ of\ the$ \\ $protocol$};
    \node[box, left=of D] (E) { $The\ two\ transcripts$ \\ $are\ compared,$ \\ $giving\ an\ output$};
    \node[box, left=of E] (F) { $The\ output\ is$ \\ $compared\ to$ \\ $the\ selection\ of$ \\ $the\ tags$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);
    \draw[arrow] (D) -- (E);
    \draw[arrow] (E) -- (F);
    \end{tikzpicture}
    \caption{Resettable state experiment}
    \end{figure}

    This experiment highlights how the Reset() oracle makes it possible to link tags. If a tag is reset then its default values and randomness
    will yield the same output, making it possible to link it to a particular tag. Even a narrow-weak adversary can use this to break privacy.

    The following scheme shows how privacy is attacked for resettable tags:

    \begin{figure}[H]
    \hspace*{0.5cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance=0.3cm and 0.5cm
    ]

    % Nodes (text boxes)
    \node[box] (A) { $A\ resets \ tag\ ID$ };
    \node[box, right=of A] (B) { $A\ eavesdrops\ a$ \\ $complete\ run$ \\ $of\ the\ protocol$};
    \node[box, right=of B] (C) { $A\ gets\ transcript\ \tau_{ID}$};
    \node[box, right=of C] (D) { $A\ links\ \tau_{ID}$ \\ $with\ tag\ ID$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);


    \end{tikzpicture}
    \caption{Resettable tag privacy attack}
    \end{figure}

\section{The impossibility results for stateless tags}

    This section covers the results for stateless tags, meaning tags that cannot update their persistent state. The less restrictive definition of this is that
    the adversary can reset only the permanent state thus making the tags use the same state multiple times. This property will lead to the 
    impossibility of destructive privacy in Vaudenay's model using such tags. 

    In a stateless RFID scheme the Free(vtag) oracle erases any temporary information stored on the tag. Thus the scheme will make use of tags that have the same
    persistent state throughout the protocol and the temporary memory is used only when communicating with a reader, when the tag is powered by it.

    Algorithm 6 presents how an adversary would interact with a scheme using stateless tags with temporary memory.

    \begin{algorithm}[H]
        \centering
        \caption{$\mathcal{A}_{prv}$ against narrow-forward privacy with stateless tags}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag(ID)
            \State $vtag \leftarrow$ DrawTag(ID)
            \State Free(vtag)  \Comment{deletes the temporary state}
            \State $vtag \leftarrow$ DrawTag(ID)
            \State $t \in \{1, ..., q_t\}$
            \State $m_1 \leftarrow SendReader(-,\pi)$ 
            \State i $\leftarrow$ 1
            \While{$i < t$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag)$ 
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile
            \State $S \gets$ \text{Corrupt}(vtag)
            \If{$temporary\ state\ of\ S = empty$}
                \State \Return 1
            \EndIf
        \end{algorithmic}
    \end{algorithm}

    However \cite{Impossibility_results} leaves us with the following lemma:

    \textbf{Lemma 2}: The temporary state of tags is always empty in any stateless narrow-forward RFID scheme. 

    This is justified through contradiction, let it be assumed the temporary state is non-empty. The outcome is that a tag would use temporary 
    variables if it would communicate with the real oracles. If the protocol would be blinded then all SendTag() calls are simulated, 
    meaning no temporary variables. An adversary would be able to distinguish between the two cases after a Corrupt() oracle query, 
    shown in algorithm 6. This is possible by guessing for the former case with non-negligible probability a protocol round where the
    tag uses temporary variables. This contradicts narrow-forward privacy, meaning Lemma 2 holds.

    Lemma 2 formally means: $(S^{\mathcal{T}_{ID}}, \cdot) \gets \mathcal{T}_{ID}^i(S^{\mathcal{T}_{ID}}, \cdot)$. Thus the scheme will 
    work with a fixed persistent state and an empty temporary state.
    
    \textbf{Theorem 4}: \textit{There is no stateless RFID scheme that achieves destructive privacy.}
    
    Destructive privacy implies forward privacy so both must be true for a scheme at the same time. For our stateless scheme it is proved in the following
    that is not the case. The proof is by contradiction so we start with the presumption of privacy and arrive at a conclusion that is false.

    A destructive privacy scheme implies the existence of a blinder $\mathcal{B}$ such that an adversary can not distinguish between the real oracles and 
    their simulation.
    Using this blinder, $\mathcal{B}_D$, a narrow-forward adversary $\mathcal{A}_{prv}^{\mathcal{B}_D}$ can be constructed. This adversary will be 
    able to thwart forward privacy, hence the contradiction.

    The scheme makes use of stateless tags, meaning the persistent memory remains the same. Let $\mathcal{T}^{i}$ be the computation done by a tag
    at the i-th SendTag() query. 

    $\mathcal{A}_{prv}$ is defined in algorithm 7.

    The idea is for the adversary $\mathcal{A}_{prv}$ to forward the messages between the tag and the reader up to a set round $j_{\mathcal{R}}$. After that $\mathcal{A}_{prv}$
    corrupts $\mathcal{T}$ and gets its state. Even though the adversary is destructive, they can compute the remaining tag steps of the protocol using the 
    obtained state and the protocol algorithm. $\mathcal{A}_{prv}$ also picks a state at random, with the same distribution as creating a new tag. 
    Then it picks randomly from the two states and continues the protocol until the end. When the randomly selected state is the one obtained by the 
    Corrupt() oracle, due to correctness the Result() query will yield 1 and for the other case the reader will reject it.

    Algorithm 7 shows that there is an adversary that can distinguish if a tag has changed its state.

    The definition for privacy states that there is a blinder $\mathcal{B}_D$ such that $Adv_{\mathcal{A}_{prv}}^{prv} = | Pr[Exp_{\mathcal{A}_{prv}}^{prv-0} = 1] - 
    Pr[Exp_{\mathcal{A}_{prv}}^{prv-1} = 1] | = \epsilon(l)$ for a negligible function $\epsilon$. If such a $\mathcal{B}_D$ exists then it can simulate the tag
    and the reader for the first $j_{\mathcal{R}}$ rounds and after can simulate the reader until the protocol terminates. Two discrete phases can be observed.
    Thus $\mathcal{B}_D$ can answer Result() queries as well as the reader and by extension can distinguish if the messages have the same origin.

    \begin{algorithm}[H]
        \centering
        \caption{$\mathcal{A}_{prv}$ against destructive privacy}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag($ID_0$)
            \State CreateTag($ID_1$)
            \State $vtag_{0} \leftarrow$ DrawTag($ID_k, Pr(k)= 1/2, k \in \{0,1\}$)
            \State $\pi \leftarrow$ Launch() 
            \State $m_1 \leftarrow SendReader(-,\pi)$ 
            \State $j_{\mathcal{R}} \in \{1, \dots, q_\mathcal{R}\}$
            \State i $\leftarrow$ 1

            \While{$i < j_{\mathcal{R}}$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag_{0})$
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile
            \State $\mathcal{S}^{\mathcal{T}_{ID}} \gets Corrupt(vtag)$
            \State $b \in \{0,1\}$
            \If{$ b = 1 $}
                \State $ m_{2j_{\mathcal{R}}} \gets \mathcal{T}^{j_{\mathcal{R}}}(\mathcal{S}^{\mathcal{T}_{ID}}, m_{2j_{\mathcal{R}}-1})$
            \Else
                \State pick a state with the same distribution as CreateTag()
                \State $\mathcal{S}^{\mathcal{T}_{ID}} \gets \mathcal{S}$
                \State $ m_{2j_{\mathcal{R}}} \gets \mathcal{T}^{j_{\mathcal{R}}}(\mathcal{S}^{\mathcal{T}_{ID}}, m_{2j_{\mathcal{R}}-1})$
            \EndIf
            \State $m_{2j_{\mathcal{R}}+1} \gets SendReader(m_{2j_{\mathcal{R}}}, \pi)$ 
            \State i $\leftarrow$ $j_{\mathcal{R}}+1$
            \While{$i < q_\mathcal{R}$}
                \State $m_{2i} \gets \mathcal{T}^{i}(\mathcal{S}^{\mathcal{T}_{ID}}, m_{2i-1})$
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$
                \State $i \gets i+1$
            \EndWhile       
            \State $return (Result(\pi) \land b) \lor (\lnot Result(\pi) \land \lnot b)$
        \end{algorithmic}
    \end{algorithm}

    Next, it is shown how a narrow-forward adversary can use $\mathcal{B}_D$ to distinguish between the blinder $\mathcal{B}$ and the real oracles. This disproves 
    narrow-forward privacy and in turn destructive privacy. $\mathcal{A}_{prv}$ uses the capabilities of $\mathcal{B}_D$ by feeding it information similarly to 
    algorithm 7. This is described in the following, algorithm 8. 

    \begin{algorithm}[H]
        \centering
        \caption{$\mathcal{A}_{prv}^{\mathcal{B}_D}$ against narrow-forward privacy}
        \begin{algorithmic}[1] % 1 -> line numbers
            \State CreateTag($ID_0$)  \Comment{shown to $\mathcal{B}_D \rightarrow 1$}
            \State CreateTag($ID_1$)  \Comment{shown to $\mathcal{B}_D \rightarrow 2$}
            \State $vtag_{0} \leftarrow$ DrawTag($ID_k, Pr(k)= 1/2, k \in \{0,1\}$)  \Comment{shown to $\mathcal{B}_D \rightarrow 3$}
            \State $\pi \leftarrow$ Launch()  \Comment{simulated by $\mathcal{B}_D \rightarrow 4$}
            \State $m_1 \leftarrow SendReader(-,\pi)$  \Comment{simulated by $\mathcal{B}_D \rightarrow 5$}
            \State $j_{\mathcal{R}} \in \{1, \dots, q_\mathcal{R}\}$
            \State i $\leftarrow$ 1

            \While{$i < j_{\mathcal{R}}$}                
                \State $m_{2i} \gets SendTag(m_{2i-1}, vtag_{0})$  \Comment{simulated by $\mathcal{B}_D \rightarrow 9$}
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$  \Comment{simulated by $\mathcal{B}_D \rightarrow 10$}
                \State $i \gets i+1$
            \EndWhile
            \State $m_{2j_{\mathcal{R}}} \gets SendTag(m_{2j_{\mathcal{R}}-1}, vtag_{0})$ \Comment{computed\ by\ $vtag_{0}\ with\ real\ oracle\ or\ blinder$}
            \State $Free(vtag_{0})$
            \State $vtag_{1} \leftarrow$ DrawTag($ID_k, Pr(k)= 1/2, k \in \{0,1\}$)
            \State $\mathcal{S}^{\mathcal{T}_{ID}} \gets Corrupt(vtag_{1})$  \Comment{shown to $\mathcal{B}_D \rightarrow 13$}
            \State $m_{2j_{\mathcal{R}}+1} \gets SendReader(m_{2j_{\mathcal{R}}}, \pi)$  \Comment{simulated by $\mathcal{B}_D \rightarrow 22$}
            \State $i \gets j_{\mathcal{R}}+1$
            \While{$i < q_\mathcal{R}$}
                \State $m_{2i} \gets \mathcal{T}^{i}(\mathcal{S}^{\mathcal{T}_{ID}}, m_{2i-1})$  \Comment{computed by $\mathcal{A}_{prv}^{\mathcal{B}_D}$}
                \State $m_{2i+1} \gets SendReader(m_{2i}, \pi)$  \Comment{simulated by $\mathcal{B}_D \rightarrow 26$}
                \State $i \gets i+1$
            \EndWhile 
            \State $b \gets Result(\pi)$  \Comment{simulated by $\mathcal{B}_D \rightarrow 29$}
            \State $return (\Gamma[vtag_{0}] = \Gamma[vtag_{1}] \land b) \lor (\Gamma[vtag_{0}] \neq \Gamma[vtag_{1}] \land \lnot b)$
        \end{algorithmic}
    \end{algorithm}

    The adversary makes $\mathcal{B}_D$ to compute the first $j_{\mathcal{R}}$ rounds of the protocol(8-12). After, $\mathcal{A}_{prv}^{\mathcal{B}_D}$ queries the 
    SendTag() oracle with message $m_{2j_{\mathcal{R}}-1}$ given by $\mathcal{B}_D$. This is the tag side of the protocol for step $j_{\mathcal{R}}$. Next the adversary
    frees $vtag_{0}$ and draws a new tag: $vtag_{1}$. Steps 13-15 are not shown to $\mathcal{B}_D$. Next $\mathcal{A}_{prv}^{\mathcal{B}_D}$ obtains the state of
    the new tag $vtag_{1}$ by corrupting it. This is shown to $\mathcal{B}_D$. $\mathcal{A}_{prv}^{\mathcal{B}_D}$ sends $\mathcal{B}_D$ the message $m_{2j_{\mathcal{R}}}$ 
    (line 13). This message has been computed either with the real oracles or via blinder $\mathcal{B}$. $\mathcal{B}_D$ expects this message to be the product of the Corrupt()
    oracle(line 12, algorithm 7).

    Until now the algorithm has computed $j_{\mathcal{R}}$ steps with a tag and 2 options discerned themselves, to continue with the original tag or choose another. The selected 
    tag will be subjected to the evaluation done by $\mathcal{B}_D$. 

    After the protocol enters phase 2 of $\mathcal{B}_D$, it plays the reader side until the end. By hypothesis $\mathcal{B}_D$ can distinguish if the messages received in the second
    phase match the behaviour of the tag from the first phase, in which case Result() will output 1 or not, and Result() will output 0. 
    
    What remains is to calculate the advantage $Adv_{\mathcal{A}_{prv}^{\mathcal{B}_D}}^{prv}$ if $\mathcal{B}_D$ exists.

    Firstly the case in which the adversary interacts with the real oracles, i.e. uses the real SendTag() oracle (line 13 of algorithm 8). If
    $\Gamma(vtag_0) = \Gamma(vtag_1)$ then by the capabilities of $\mathcal{B}_D$ the Result query returns 1 with overwhelming probability, which
    leads to $\mathcal{A}_{prv}^{\mathcal{B}_D}$ returning 1 by the same probability. Even though $\mathcal{B}_D$ receives the state
    $\mathcal{S}^{\mathcal{T}_{ID}}$ after the first phase by the property of Lemma 2, the state is the same as in the beginning of the protocol.
    If $\Gamma(vtag_0) \neq \Gamma(vtag_1)$ then the messages in the first phase were computed to the state of one vtag and the rest were computed
    to the state of a vtag identifying another tag. This is not what $\mathcal{B}_D$ expects (Corrupt() gives the state of another tag) and it could wrongly output 1. Let p be the probability
    of $\mathcal{B}_D$ outputting 0 after $j_\mathcal{R}$ messages computed with a random state and the rest computed by an arbitrary state 
    $\mathcal{S}^{\mathcal{T}_{ID}}$. Thus $Pr[Exp_{\mathcal{A}_{prv}^{\mathcal{B}_D}}^{prv-0} = 1] = \frac{1}{2}*(1-\epsilon(l))
    +\frac{1}{2}*p \leq \frac{(1+p)}{2}.$

    Next, we study the case where $\mathcal{A}_{prv}$ interacts with a blinder $\mathcal{B}$. For the both cases: $\Gamma(vtag_0) = \Gamma(vtag_1)$ and 
    $\Gamma(vtag_0) \neq \Gamma(vtag_1)$ the output of the SendTag() query computed by $\mathcal{B}_D$ is by way of a random state that is
    with overwhelming probability different from $vtag_0$ or $vtag_1$. Thus in both cases $j_\mathcal{R}$ messages are computed with a random 
    state different than $\mathcal{S}^{\mathcal{T}_{ID}}$ and the rest computed by an arbitrary state $\mathcal{S}^{\mathcal{T}_{ID}}$. Therefore 
    $Pr[Exp_{\mathcal{A}_{prv}^{\mathcal{B}_D}}^{prv-1} = 1] = \frac{1}{2}*(1-p)+\frac{1}{2}*p = \frac{(1-p)}{2}+\frac{p}{2} = \frac{1}{2}.$
    What follows is that $Adv_{\mathcal{A}_{prv}^{\mathcal{B}_D}}^{prv} \leq | \frac{(1+p)}{2} - \frac{1}{2} | = \frac{p}{2}$. Given the way in 
    which probability p is defined and the fact that $\mathcal{B}_D$ is able to distinguish if a state changed through a protocol instance then
    p is non-negligible and so is $Adv_{\mathcal{A}_{prv}^{\mathcal{B}_D}}^{prv}$, concluding the proof. 

    Scheme 3.5 presents the interaction between $\mathcal{A}_{prv}^{\mathcal{B}_D}$ and the blinder $\mathcal{B}_D$.

    \begin{figure}[H]
    \hspace*{-0cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance=0.3cm and 0.5cm
    ]
    
    % Nodes (text boxes)
    \node[box] (A) { $A\ creates\ two$ \\ $tags\ ID_0\ and\ ID_1$ };
    \node[box, below=of A] (B) { $A\ draws\ one\ tag$ \\ $at\ random:\ vtag_0$};
    \node[box, below=of B] (C) { $A\ executes\ j_R\ steps$ \\ $of\ the\ protocol$ \\ $with\ \mathcal{B}_D$};
    \node[box, below=of C, xshift=-4cm] (D) { $A\ obtains\ the\ last\ m_{2j_R}$ \\ $message\ from\ vtag_0$ \\ $with\ the\ \textbf{real oracle}$};
    \node[box, below=of C, xshift= 4cm] (E) { $A\ obtains\ the\ last\ m_{2j_R}$ \\ $message\ from\ vtag_0$ \\ $with\ the\ \textbf{blinder}$};
    \node[box, below=of D] (F) { $A\ frees\ vtag_0$};
    \node[box, below=of E] (G) { $A\ frees\ vtag_0$};
    \node[box, below=of F] (H) { $ID_0\ or\ ID_1$ \\ $will\ be\ selected$};
    \node[box, below=of G] (I) { $ID_0\ or\ ID_1$ \\ $will\ be\ selected$};
    \node[box, below =of H, xshift=-2cm] (J) { $A\ draws\ vtag_1$ \\ $\Gamma(vtag_0)=\Gamma(vtag_1)$};
    \node[box, below =of H, xshift= 2cm] (K) { $A\ draws\ vtag_1$ \\ $\Gamma(vtag_0) \neq \Gamma(vtag_1)$};
    \node[box, below =of I, xshift=-2cm] (L) { $A\ draws\ vtag_1$ \\ $\Gamma(vtag_0)=\Gamma(vtag_1)$};
    \node[box, below =of I, xshift= 2cm] (M) { $A\ draws\ vtag_1$ \\ $\Gamma(vtag_0) \neq \Gamma(vtag_1)$};
    \node[box, below =of J] (N) {$A\ corrupts\ and$ \\ $gets\ state\ S^{T_{ID}}$};
    \node[box, below =of K] (O) {$A\ corrupts\ and$ \\ $gets\ state\ S^{T_{ID}}$};
    \node[box, below =of L] (P) {$A\ corrupts\ and$ \\ $gets\ state\ S^{T_{ID}}$};
    \node[box, below =of M] (Q) {$A\ corrupts\ and$ \\ $gets\ state\ S^{T_{ID}}$};
    \node[box, below =of N] (R) {$m_{2j_R}\ is\ sent$ \\ $to\ blinder\ \mathcal{B}_D$};
    \node[box, below =of O] (S) {$m_{2j_R}\ is\ sent$ \\ $to\ blinder\ \mathcal{B}_D$};
    \node[box, below =of P] (T) {$m_{2j_R}\ is\ sent$ \\ $to\ blinder\ \mathcal{B}_D$};
    \node[box, below =of Q] (U) {$m_{2j_R}\ is\ sent$ \\ $to\ blinder\ \mathcal{B}_D$};
    \node[box, below =of R] (rest_1) {$A\ executes\ the$ \\ $rest\ of\ the\ protocol$ \\ $and\ gets\ the\ result$ \\ $of\ blinder\ \mathcal{B}_D$};
    \node[box, below =of S] (rest_2) {$A\ executes\ the$ \\ $rest\ of\ the\ protocol$ \\ $and\ gets\ the\ result$ \\ $of\ blinder\ \mathcal{B}_D$};
    \node[box, below =of T] (rest_3) {$A\ executes\ the$ \\ $rest\ of\ the\ protocol$ \\ $and\ gets\ the\ result$ \\ $of\ blinder\ \mathcal{B}_D$};
    \node[box, below =of U] (rest_4) {$A\ executes\ the$ \\ $rest\ of\ the\ protocol$ \\ $and\ gets\ the\ result$ \\ $of\ blinder\ \mathcal{B}_D$};
    \node[box, below =of rest_1] (result_1) {$A\ gets\ result$ \\ $with\ probability$ \\ $ \approx 1$};
    \node[box, below =of rest_2] (result_2) {$A\ gets\ result$ \\ $with\ probability$ \\ $p$};
    \node[box, below =of rest_3] (result_3) {$A\ gets\ result$ \\ $with\ probability$ \\ $1-p$};
    \node[box, below =of rest_4] (result_4) {$A\ gets\ result$ \\ $with\ probability$ \\ $p$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);
    \draw[arrow] (C) -- (E);
    \draw[arrow] (D) -- (F);
    \draw[arrow] (E) -- (G);
    \draw[arrow] (F) -- (H);
    \draw[arrow] (G) -- (I);
    \draw[arrow] (H) -- (J);
    \draw[arrow] (H) -- (K);
    \draw[arrow] (I) -- (L);
    \draw[arrow] (I) -- (M);
    \draw[arrow] (J) -- (N);
    \draw[arrow] (K) -- (O);
    \draw[arrow] (L) -- (P);
    \draw[arrow] (M) -- (Q);
    \draw[arrow] (N) -- (R);
    \draw[arrow] (O) -- (S);
    \draw[arrow] (P) -- (T);
    \draw[arrow] (Q) -- (U);
    \draw[arrow] (R) -- (rest_1);
    \draw[arrow] (S) -- (rest_2);
    \draw[arrow] (T) -- (rest_3);
    \draw[arrow] (U) -- (rest_4);
    \draw[arrow] (rest_1) -- (result_1);
    \draw[arrow] (rest_2) -- (result_2);
    \draw[arrow] (rest_3) -- (result_3);
    \draw[arrow] (rest_4) -- (result_4);

    \end{tikzpicture}
    \caption{Stateless tags experiment}
    \end{figure}

    An adversary can feed the blinder against destructive privacy $\mathcal{B}_D$ in such a way that the results of the experiment with stateless tags
    are produced by different distributions. These probabilities point to a difference between real and random states, thus making possible to draw non-trivial 
    relations between tags. This is a breach of privacy and it is shown in figure 3.6.

    \begin{figure}[H]
    \hspace*{0.5cm}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=black, thick, minimum height=1cm, minimum width=2.5cm, align=center},
        arrow/.style={-Latex, thick},
        node distance = 1.3cm and 1cm
    ]

    % Nodes (text boxes)
    \node[box] (A) { $A\ creates\ and$ \\ $draws\ tag\ ID$ };
    \node[box, right=of A] (B) { $A\ uses\ \mathcal{B}_D\ for\ an\ arbitrary$ \\ $number\ j_k\ of\ protocol$ \\ $ steps\ with\ tag\ ID$};
    \node[box, right=of B] (C) { $A\ computes\ message$ \\ $m_{2j_R}\ with\ the$ \\ $real\ oracle/state$};
    \node[box, below=of C] (D) { $A\ frees\ vtag_0$};
    \node[box, left =of D, xshift= -1cm] (E) { $A\ draws\ an$ \\ $arbitrary\ tag$ \\ $\Gamma(vtag_0) \stackrel{?}{=}\ \Gamma(vtag_1)$};
    \node[box, left =of E, xshift= -0.8cm] (F) {$A\ corrupts\ and$ \\ $gets\ state\ S^{T_{ID}}$};
    \node[box, below=of F, yshift= -0.8cm] (G) {$m_{2j_R}\ is\ sent$ \\ $to\ blinder\ \mathcal{B}_D$};
    \node[box, right=of G, xshift=  0.8cm] (H) {$A\ executes\ the\ rest$ \\ $of\ the\ protocol\ with$ \\ $S^{T_{ID}}\ and\ gets\ the$ \\ $result\ of\ blinder\ \mathcal{B}_D$};
    \node[box, right=of H] (I) {$A\ gets\ result\ with$ \\ $an\ arbitrary\ probability$};

    % Arrows
    \draw[arrow] (A) -- (B);
    \draw[arrow] (B) -- (C);
    \draw[arrow] (C) -- (D);
    \draw[arrow] (D) -- (E);
    \draw[arrow] (E) -- (F);
    \draw[arrow] (F) -- (G);
    \draw[arrow] (G) -- (H);
    \draw[arrow] (H) -- (I);

    \end{tikzpicture}
    \caption{Stateless tag privacy attack}
    \end{figure}

    